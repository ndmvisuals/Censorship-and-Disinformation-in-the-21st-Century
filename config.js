var config = {
  style: "mapbox://styles/ndmvisuals/ckxiidu6484cs17pefj3z2c05",
  accessToken:
    "pk.eyJ1IjoibmRtdmlzdWFscyIsImEiOiJja3hpaG9vaHIya3JsMm5zdGI5OGJnMTBhIn0.IzoHnVuSOWcMTZH0Rq-4yw",
  showMarkers: "false",
  theme: "dark",
  alignment: "left",
  title: "Censorship and Disinformation in the 21st Century ",
  subtitle: "The New Global War for Political Power",
  byline:
    "By Nicholas McMillan, Glory Ngwe, Natalie Drum, Brittany Gaddy, Jack White, and Kelly Livingston",
  footer: "Source: Class of Dana Priest",
  chapters: [
    {
      id: "Intro",
      title: "Intro",
      image: "https://raw.githubusercontent.com/ndmvisuals/Censorship-and-Disinformation-in-the-21st-Century/main/photos/MerrillCollegeLogo.png",
      description:
        "Disinformation and censorship are the weapons of choice in the war for political power. Leaders in both democratic and authoritarian countries use the internet, social media and bots to control the flow of information. The following interactive map summarizes some of the main themes and events covered in Dana Priest's class at the Philip Merrill College of Journalism. By understanding the history of disinformation and the tools used today to spread it, journalists will be better prepared against attacks on the freedom of the press.",
      location: {
        center: { lon: 64.19013, lat: 0.00000 },
zoom: 1.37,
pitch: 0.50,
bearing: 0.00
      },
      onChapterEnter: [
        // {
        //     layer: 'layer-name',
        //     opacity: 1
        // }
      ],
      onChapterExit: [
        // {
        //     layer: 'layer-name',
        //     opacity: 0
        // }
      ]
    },
    {
      id: "Russia 1",
      title: "USSR - Active Measures",
      image: "https://raw.githubusercontent.com/ndmvisuals/Censorship-and-Disinformation-in-the-21st-Century/main/photos/Soviet%20active%20measures.png",
      description: "Active measures is a Soviet term that refers to the manipulative use of slogans, arguments, disinformation, and carefully selected true information, which the Soviets used to try to influence the attitudes and actions of foreign publics and governments, according to Soviet Active Measures in the “Post-Cold War” Era. While anti-American disinformation decreased during the late 1980s and early 1990s, another form of derogatory disinformation increased. As the Soviet Communist Party loosened its rigid totalitarian grip within the USSR, it tried to compensate for this by increasing its use of defamatory disinformation against its domestic adversaries, including Russian president Boris Yeltsin, Lithuanian president, Vytautas Landsbergis, and other democratic and nationalist opponents of the Soviet Comnunist Party.",
      location: {
        center: { lon: 65.64555, lat: 59.82731 },
        zoom: 2.71,
        pitch: 0.00,
        bearing: 0.00
      },
      onChapterEnter: [],
      onChapterExit: []
    },
    
    {
      id: "Russia 2",
      title: "USSR - Active Measures Part Two",
      image: "https://raw.githubusercontent.com/ndmvisuals/Censorship-and-Disinformation-in-the-21st-Century/main/photos/Gorbachev%20at%20the%20united%20nations.png",
      description: "<p> (<a href = 'https://www.c-span.org/video/?5292-1/gorbachev-united-nations' target= '_blank'>Photograph:</a> C-SPAN)  </p> In 1990 and 1991, the Soviets spread alarmist active measures themes energetically, as they attempted to turn to their advantage Western fears about the dangers of a break-up of the USSR. According to a recent defector who circulated active measures for the KGB during this period, the Soviet authorities deliberately sought to influence Western policy by encouraging the belief that if Gorbachev were to lose power or the USSR were to break up, this would lead to the creation of aggressive republics with uncontrolled access to nuclear weapons. All in all, the most pervasive tlpe of active measure during the post-Cold War era was exemplified by the conciliatory slogans of “new political thinking,” according to Soviet Active Measures in the “Post-Cold War” Era. The Soviet thinking behind the adoption of new thinking was counterintuitive to Westerners. According to the Soviets, Western economic superiority, rearmament, and the specter of a Strategic Defense Initiative with which they could not compete forced them in the mid 1980s to abandon their decades-long effort to gain military superiority over the West. Rather than abandon their ambitious goals in the world arena, however, they made the desperate but audacious decision to try to achieve them by conciliatory, political means rather than the predominantly military, confrontational methods of the past.",
      location: {
        center: { lon: 37.61963, lat: 55.76932 },
zoom: 9.22,
pitch: 34.50,
bearing: 0.00
      },
      onChapterEnter: [],
      onChapterExit: []
    },
    
     {
      id: "Russia 3",
      title: "St. Petersburg - Internet Research Agency (IRA):",
      image: "https://raw.githubusercontent.com/ndmvisuals/Censorship-and-Disinformation-in-the-21st-Century/main/photos/IRA%20office%20building.jpeg",
      description: "<p> (<a href = 'https://www.theguardian.com/world/2015/apr/02/putin-kremlin-inside-russian-troll-house' target= '_blank'>Photograph:</a> Shaun Walker/Guardian)  </p> The Internet Research Agency is a Russian troll farm in St. Petersburg—in essence a Kremlin-backed enterprise staffed with hundreds of people whose main job is to sow disinformation on the internet. The organization, which serves as a propaganda arm for Russian President Vladimir Putin, is at the heart of the indictments handed down by Special Counsel Robert Mueller. The agency had become known for employing hundreds of Russians to post pro-Kremlin propaganda online under fake identities, including on Twitter, in order to create the illusion of a massive army of supporters. This building full of bloggers and meme-makers used Facebook, Twitter, Pinterest, Reddit, and other social media platforms to spread articles, memes, and other web-based information with the sole purpose of creating chaos in the U.S. The primary goal of this agency was to influence online engagement in favor of Russian political and economic interests.",
      location: {
center: { lon: 30.27209, lat: 59.98428 },
zoom: 15.80,
pitch: 34.50,
bearing: 0.00
      },
      onChapterEnter: [],
      onChapterExit: []
    },
    
    {
      id: "Russia 4",
      title: "Beslan",
      image: "https://raw.githubusercontent.com/ndmvisuals/Censorship-and-Disinformation-in-the-21st-Century/main/photos/Beslan%20wounded%20child.jpg",
      description: "<p> (Photograph: Ivan Sekretarev/AP) </p> A massive and destructive news blackout in a town in the North Ossetian Republic in Russia; the scene of the massacre in 2004 when Chechen extremists held a school hostage, leading to a siege in which nearly 350 people were killed. By September 3, the families of hostages were in a total news blackout. They were desperate; they all remember the experience of the Dubrovka theater siege in which 129 people died when the special services released gas into the building, ending the stand-off. They remember how the government lied, according to The Guardian. The events in Beslan have shown that the consequences of an information vacuum are disastrous. People dismiss the state that has left them in the lurch and try to act on their own, try to rescue their loved ones themselves, and to exact their own justice on the culprits. Later, Putin declared that the Beslan tragedy had nothing to do with the Chechen crisis, so the media stopped covering the topic. So Beslan is like September 11: all about al-Qaeda.",
      location: {
center: { lon: 44.51741, lat: 43.28106 },
zoom: 7.15,
pitch: 19.50,
bearing: -1.08
      },
      onChapterEnter: [],
      onChapterExit: []
    },

    {
      id: "Estonia 1",
      title: "The Bronze Knight",
      image:
        "https://raw.githubusercontent.com/ndmvisuals/Censorship-and-Disinformation-in-the-21st-Century/main/photos/The%20Bronze%20Soldier%20of%20Tallinn.png",
      description:
        "<p> (Photograph: Atlas Obscura) </p> In 1990 and 1991, the Soviets spread alarmist active measures themes energetically, as they attempted to turn to their advantage Western fears about the dangers of a break-up of the USSR. According to a recent defector who circulated active measures for the KGB during this period, the Soviet authorities deliberately sought to influence Western policy by encouraging the belief that if Gorbachev were to lose power or the USSR were to break up, this would lead to the creation of aggressive republics with uncontrolled access to nuclear weapons. All in all, the most pervasive tlpe of active measure during the post-Cold War era was exemplified by the conciliatory slogans of “new political thinking,” according to Soviet Active Measures in the “Post-Cold War” Era. The Soviet thinking behind the adoption of new thinking was counterintuitive to Westerners. According to the Soviets, Western economic superiority, rearmament, and the specter of a Strategic Defense Initiative with which they could not compete forced them in the mid 1980s to abandon their decades-long effort to gain military superiority over the West. Rather than abandon their ambitious goals in the world arena, however, they made the desperate but audacious decision to try to achieve them by conciliatory, political means rather than the predominantly military, confrontational methods of the past.",
      location: {
        center: { lon: 25.81096, lat: 58.92103 },
        zoom: 5.98,
        pitch: 0.0,
        bearing: 0.0
      },
      onChapterEnter: [],
      onChapterExit: []
    },

    {
      id: "Estonia 2",
      title:
        "Russia’s first foreign disinformation operation in Estonia",
      image:
        "https://raw.githubusercontent.com/ndmvisuals/Censorship-and-Disinformation-in-the-21st-Century/main/photos/Estonian%20police%20clash%20with%20pro-Russian%20demonstrators.jpg",
      description:
        "<p> (Photograph: Raigo Pajula/AFP/Getty Images) </p> Russia’s first foreign disinformation operation in Estonia started when the Estonian government announced the re-location of the statue and Russian media told people the statue was being demolished rather than re-located. Protests erupted and bot’s flooded Estonian government and public service networks aiming to confuse and misinform the public. After three days of violent protests, Estonia was forced to pull the plug on severed electronic connections to halt any continued cyber attacks. For this disinformation campaign, the Russians depended on the fact that Russian-speaking Estonians got their news from Russian media. ",
      location: {
        center: { lon: 24.74523, lat: 59.43811 },
        zoom: 12.73,
        pitch: 60.00,
        bearing: 0.00
      },
      onChapterEnter: [],
      onChapterExit: []
    },
    
    {
      id: "Ukraine 1",
      title:
        "MH17",
      image:
        "https://raw.githubusercontent.com/ndmvisuals/Censorship-and-Disinformation-in-the-21st-Century/main/photos/MH17.jpg",
      description:
        " <p> (Photograph: REUTERS/Piroschka van de Wouw/Pool) </p> In 2014, Malaysian Airlines Boeing 777 crashed in Donbas, Ukraine.  All 298 people on board the MH17 died. An investigation two years later concluded the plane was shot down by an air missile fired from a Russian-backed territory in eastern Ukraine. Prior to the investigation, many conspiracy theories arose about how the MH17 crashed, including a theory by an alleged air-traffic controller who claimed a military jet took the plane down. This gave the false impression that Ukraine was responsible for the incident and the story spread. Bots were used to help block journalists’ Facebook accounts who were posting about MH17. And after the plane crash’s official investigation, bots replied to tweets in Russian that used the #MH17 hashtag with fake articles that questioned the investigation’s results, further spreading disinformation.",
      location: {
        center: { lon: 26.82509, lat: 49.50637 },
zoom: 4.57,
pitch: 0.00,
bearing: 0.00
      },
      onChapterEnter: [],
      onChapterExit: []
    },
    
     {
      id: "Ukraine 2",
      title:
        "Carlos",
      image:
        "https://raw.githubusercontent.com/ndmvisuals/Censorship-and-Disinformation-in-the-21st-Century/main/photos/Carlos.png",
      description:
        "<p> (Photograph: Radio Free Europe Radio Liberty) </p> “Carlos” is an alleged Spanish air-traffic controller who authored Tweets that falsely suggested Ukraine was responsible for the MH17 crash in 2014. “Carlos” claimed to have been working in the Kyiv Boryspil Airport when he saw a military aircraft in the area of the crash. His series of Tweets suggested Ukraine shot down the plane. The false story was shared by RT, a Russian channel, and other news outlets. StopFake, a fact-checking website, later conducted an investigation that proved “Carlos” was fake because Ukraine prevents non-Ukrainian citizens from working as flight operation officers. Leading to the MH17 crash, research by the Ukrainian deputy minister of information policy showed “Carlos” actively retweeted pro-Russian messages.",
      location: {
        center: { lon: 30.89586, lat: 50.35243 },
zoom: 10.59,
pitch: 38.50,
bearing: 0.00
      },
      onChapterEnter: [],
      onChapterExit: []
    },
    
    {
      id: "Ukraine 3",
      title:
        "Maidan Revolution",
      image:
        "https://raw.githubusercontent.com/ndmvisuals/Censorship-and-Disinformation-in-the-21st-Century/main/photos/Maidan%20revolution.jpg",
      description:
        " <p> (Photograph: Snig/Shutterstock)  </p> On Nov. 21, 2013, Ukraine announced it would suspend plans to enter an agreement with the European Union, which would have further unified political and economic ties between the EU and Ukraine. Then-president Victor Yanukovych succumbed to pressure from Russia not to sign it. In response, Ukrainians gathered in Kyiv in protest and called on Yanukovych to resign. In early 2014, the government introduced laws restricting the right to protest, which were met by more protests. Over 100 people died; most were civilians. Yanukovych ended up fleeing the country and parliament voted to remove him. On May 25, 2014, Petro Poroshenko was voted president. Parliament also created a new government that came into power later that year.",
      location: {
        center: { lon: 30.52906, lat: 50.45089 },
zoom: 5.57,
pitch: 0.50,
bearing: -0.67
      },
      onChapterEnter: [],
      onChapterExit: []
    },
    
    {
      id: "Ukraine 4",
      title:
        "Crimea",
      image:
        "https://raw.githubusercontent.com/ndmvisuals/Censorship-and-Disinformation-in-the-21st-Century/main/photos/Crimea.jpg",
      description:
        "<p> (<a href = 'https://www.nytimes.com/2015/03/10/world/europe/putin-contrary-to-earlier-assertions-suggests-planning-to-seize-crimea-started-in-early-2014.html' target= '_blank'>Photograph:</a> Sergey Ponomarev/The New York Times)  </p> After then-Ukrainian President Victor Yanukovych fled the country during the Maidan Revolution, pro-Russian separatists occupied essential facilities and checkpoints in Crimea. Aided by Russian troops, they declared independence from Kyiv. Then on March 16, 2014, Crimeans voted for their region to join Russia. The western world views Crimea’s vote to secede from Ukraine as illegitimate, in part because it was illegal under Ukrainian law and hostile Russian military troops occupied Crimea without international monitoring. There were also many reports of intimidation from the Russian military.  ",
      location: {
        center: { lon: 34.19027, lat: 45.44027 },
zoom: 5.78,
pitch: 0.50,
bearing: 0.00
      },
      onChapterEnter: [],
      onChapterExit: []
    }, 
    
    {
      id: "United States 1",
      title:
        "Russia Meddling in Election",
      image:
        "https://raw.githubusercontent.com/ndmvisuals/Censorship-and-Disinformation-in-the-21st-Century/main/photos/Hillary%20mask%20at%20trump%20rally.jpg",
      description:
        "<p> (Photograph: RJ Sangosti/Denver Post via Getty Images)  </p> The Office Director of National Intelligence of the United States assessed the motivation and scope of Russia’s actions, capabilities and intentions regarding the 2016 U.S. presidential election. The intelligence committee assessed that Vladimir Putin ordered an influence campaign to undermine the American people’s faith in its democratic process and stop Clinton from taking office. The Russian Government preferred Donald Trump and it’s tactics included both overt and covert strategies, whether through paid social media trolls or through third-party intermediaries. One example is that Russian military intelligence used DCLeaks.com and Guccifer 2.0 persona to publish US victim data taken in cyber operations as well as relayed material to WikiLeaks. After an extensive investigation, special counsel Robert Mueller did not uncover any evidence that the Trump campaign conspired with Russians to influence the 2016 election.",
      location: {
        center: { lon: -97.77158, lat: 40.11608 },
zoom: 3.46,
pitch: 0.50,
bearing: 0.00
      },
      onChapterEnter: [],
      onChapterExit: []
    },
    
     {
      id: "United States 2",
      title:
        "Bots",
      image:
        "https://raw.githubusercontent.com/ndmvisuals/Censorship-and-Disinformation-in-the-21st-Century/main/photos/Vote%20by%20text.png",
      description:
        "<p> (<a href = 'https://www.cjr.org/tow_center/6_types_election_fake_news.php' target= '_blank'>Photograph:</a> Columbia Journalism Review)  </p> Bots are defined as internet applications that perform automotive and simple tasks much faster than a person could. There are three main types of bots: political bots, crawler bots and volunteer bots. Crawlers account for more online traffic than humans. Like many bots, trolls also play a role in spreading disinformation and false news. During the 2016 presidential election, a suspicious post was spread around Twitter “reminding” democrats that they are able to vote over the phone by text. In fact, no state allowed people to vote through text but many fell for that misinformation. This was caused by what is called “political bots” made to manipulate public opinion.",
      location: {
        center: { lon: -77.03701, lat: 38.89776 },
zoom: 10.90,
pitch: 0.50,
bearing: 0.00
      },
      onChapterEnter: [],
      onChapterExit: []
    },
    
    {
      id: "United States 3",
      title:
        "Facebook",
      image:
        "https://raw.githubusercontent.com/ndmvisuals/Censorship-and-Disinformation-in-the-21st-Century/main/photos/Facebook.png",
      description:
        "<p> (Photograph: Andrew Harnik/Associate Press)  </p>Facebook allows people to connect on a greater scale but aspects like user anonymity, lack of monitoring or removing inappropriate or misleading posts make it easier to spread false information or hate speech. Sophie Zhang, a former Facebook data scientist, revealed the company’s lack of mitigating and removing misleading information that influence political elections through an extremely lengthy memo. These manipulations were found in several countries including Spain, Brazil, Ukraine, India, etc. One example of misleading information that Zhang mentioned was the mass liking of Honduran president Juan Orlando Hernández’s facebook posts. The president’s Facebook administrator created over hundreds of fake pages to boost Hernández’s posts which bumped them up the newsfeed and made him seem much more popular than he was.",
      location: {
        center: { lon: -122.01083, lat: 37.41167 },
zoom: 8.58,
pitch: 0.50,
bearing: 0.00
      },
      onChapterEnter: [],
      onChapterExit: []
    },
    
    
    {
      id: "United States 4",
      title:
        "Section 230",
      image:
        "https://raw.githubusercontent.com/ndmvisuals/Censorship-and-Disinformation-in-the-21st-Century/main/photos/Section%20230.png",
      description:
        " <p> (Photograph: Brookings Institution)  </p>The Communications Decency Act (CDA) of 1996’s section 230, is a rule that aims to protect freedom of expression and innovation on the internet. The section states that “No provider or user of an interactive computer service shall be treated as the publisher or speaker of any information provided by another information content provider.” So, online platforms can not be held legally responsible for the wide range of content that others post on their platform. This is a complex rule that many have differing opinions on.",
      location: {
        center: { lon: -97.77158, lat: 40.11608 },
zoom: 3.46,
pitch: 0.50,
bearing: 0.00
      },
      onChapterEnter: [],
      onChapterExit: []
    },
    
    {
      id: "Myanmar 1",
      title:
        "Myanmar Genocide",
      image:
        "https://raw.githubusercontent.com/ndmvisuals/censorship-and-disinformation-in-the-21st-century/main/photos/Myanmar%201.jpg",
      description:
        "<p> (<a href = 'https://www.nytimes.com/2017/12/29/insider/a-desperate-trek-toward-misery-and-resignation-capturing-the-plight-of-the-rohingya.html' target= '_blank'>Photograph:</a> Tomas Munita for The New York Times)  </p> Rohingya Muslims have been discriminated against in Myanmar for decades. The government has subjected the religious minority group to violence and discrimination, even going so far as not to count them in the nation’s most recent census and denying them participation in the electoral process. In 2016, the violence against the group escalated when the military cracked down after a small contingent of insurgents mounted an attack on border posts and killed several police officers. Thousands of Rohingya people have been killed in what has been labeled a genocide by the United Nations. Hundreds of thousands of others have fled the nation in search of refuge.",
      location: {
        center: { lon: 96.45539, lat: 22.39055 },
zoom: 4.21,
pitch: 0.50,
bearing: 0.00
      },
      onChapterEnter: [],
      onChapterExit: []
    },
    
    
     {
      id: "Myanmar 2",
      title:
        "Facebook in Myanmar",
      image:
        "https://raw.githubusercontent.com/ndmvisuals/censorship-and-disinformation-in-the-21st-century/main/photos/Myanmar%202.jpg",
      description:
        "<p> (<a href = 'https://www.theguardian.com/world/2017/sep/07/massacre-at-tula-toli-rohingya-villagers-recall-horror-of-myanmar-army-attack' target= '_blank'>Photograph:</a> K.m. Asad/AFP/Getty Images)  </p> Since it first arrived in the nation in 2012, Facebook in Myanmar has been conflated with the Internet by its residents. The platform’s newsfeed algorithm has been blamed for fueling hate speech, discrimination and violence against the Rohingya people. Propaganda led against the group by military leaders and members using fake accounts went largely undetected by the platform and was designed to be incendiary. The social media company acknowledged in 2018 that it was too slow to act in Myanmar, after hundreds of thousands of Rohingya had already fled. Facebook is now being sued by Rohingya refugees for over $150 billion for its role in the persecution and genocide of the group.",
      location: {
        center: { lon: 92.77758, lat: 20.80319 },
zoom: 7.45,
pitch: 0.50,
bearing: 0.00
      },
      onChapterEnter: [],
      onChapterExit: []
    },
    
    
    
  ]
};
